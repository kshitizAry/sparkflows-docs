Read and Write to S3 Buckets
========================

Fire is fully integrated with AWS S3. The Dataset processors offered by Fire allows users to read from and write to S3 bucket directly, if the policies allow them to. Not only this, these processors can be used to save ML Models directly to S3 Buckets.

This document throws light on the below topics:

#. Configure Fire Insights
#. Read from S3 bucket
#. Write to S3 bucket
#. Save ML Models to S3 bucket

**Configure Fire Insights**
------------------

Fire needs to be configured before you can read and write to S3 bucket.

To know about the configuration details and steps to follow, read :ref:`Fire configurations for AWS S3.<Fire Configurations for S3>`

**Read from S3 bucket**
------------
Fire allows users to read from S3 bucket through various dataset processors, some of which are:

* **Read CSV**: Reads data in CSV file format.
* **Read Parquet**: Reads data in Parquet file format.
* **Read JSON**: Reads data  in JSON file format.
* **Read XML**: Reads data in XML file formats.

To learn more about the usage of dataset structured processors visit :ref:`reading structured files.<Read Structured Files>`

Now, let us try to understand the process of reading through simple steps.

**Steps to read from S3**
+++++

#. **Create** the workflow by adding processors. 
   
   We have created the workflow using *Read CSV* and *Print N Rows* processors.
   
   This workflow reads data in CSV file format from S3 bucket.

   .. figure:: ../../_assets/aws/read-from-s3-wf.png
      :alt: S3 Workflow
      :width: 65%
   
#. **Configure** the Read CSV processor to specify the path of S3 location from where you want to read the file.

   Note: We have specified the path as: ``s3a://sparkflow-sample-data/data/housing.csv``.
   
   .. figure:: ../../_assets/aws/read-config.png
      :alt: S3 CSV Dialog
      :width: 65%

#. **Save** the workflow and **execute** it to view the output.
   
   .. figure:: ../../_assets/aws/read-output.png
      :alt: S3 CSV Output
      :width: 65%
    
   
**Write to S3 Bucket**
----------

Fire allows users to write to S3 bucket through various dataset processors, some of which are:

* **Save CSV**: Writes data in CSV file format to S3 bucket.
* **Save Parquet**: Writes data in Parquet file format.
* **Save Excel**: Writes data in Excel file format. 
* **Save Avro**: Writes data in Avro file format.

To learn more about the usage of dataset structured processors visit :ref:`save files.<Save Files>`

Now, let us try to understand the process of writing through simple steps.

**Steps to write to S3**
+++++

#. **Create** the workflow by adding processors. 
   
   We have created the workflow using *Read CSV* and *Save CSV* processors.
   
   This workflow reads CSV file and saves it to specified S3 path.
   
   .. figure:: ../../_assets/aws/write-to-s3-wf.png
      :alt: S3 Workflow
      :width: 65%

#. **Configure** the Save CSV processor to specify the path of S3 location where you want to write or save the file.

   Note: We have specified the path as: ``s3a://sparkflow-sample-data/write/``.
   
   .. figure:: ../../_assets/aws/save-config.png
      :alt: S3 CSV Output
      :width: 65% 

#. **Save** the workflow and **execute** it to save the file to S3 location.
   
   .. figure:: ../../_assets/aws/save_execution.PNG
      :alt: S3 CSV Output
      :width: 65% 

#. After successful completion of the above workflow, the saved data can be viewed at **DATABROWSERS/AWS S3** with specified path.

   .. figure:: ../../_assets/aws/browse_s3.PNG
      :alt: S3 Workflow
      :width: 65%



Save ML Model to S3
========================


**Save Spark ML Model**
---------------------

Fire allows users to save the Spark ML models to S3 bucket with the use of **ML Model Save** processor.

Here, we try to explain the details of configuration settings with the help of a sample workflow.

**Workflow**
+++++

Below is the sample workflow where data is read from S3 and the final Spark ML model is saved to S3 location.

  .. figure:: ../../_assets/aws/spark-model-save-wf.png
     :alt: Spark ML Workflow
     :width: 65%

**Configuration of Read CSV processor**
++++++

  .. figure:: ../../_assets/aws/ml-read-config.png
     :alt: Spark ML Workflow
     :width: 65%
 

**Configuration of ML Model Save processor**
+++++++

   .. figure:: ../../_assets/aws/ml-model-save-config.png
      :alt: Spark ML Workflow
      :width: 65%


**Execution Result**
+++++

   .. figure:: ../../_assets/aws/spark-ml-wf-execution.PNG
      :alt: Spark ML Workflow
      :width: 65%
   
**Save H20 ML Model**
---------------------

Fire allows users to save the H2O ML models to S3 bucket with the use of **H20 ML Model Save** processor.

Here, we try to explain the details of configuration settings with the help of a sample workflow.


**Workflow**
++++++

Below is the sample workflow where final H20 ML model is saved to S3 location.

   .. figure:: ../../_assets/aws/h2o-wf.png
      :alt: H20 ML Workflow
      :width: 65%

**Configuration of H2O ML Model Save processor**
++++++++

   .. figure:: ../../_assets/aws/h2o-model-save-config.png
      :alt: H20 ML Workflow   
      :width: 65%


**Execution Result**
++++++

   .. figure:: ../../_assets/aws/h20ml-workflow-execution-result.PNG
      :alt: H20 ML Workflow
      :width: 65%
   
