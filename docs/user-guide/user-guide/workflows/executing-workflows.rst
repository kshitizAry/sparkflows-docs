Executing Workflows
===================

The ways in which the Fire workflows can be executed are: 
 
 * **Interactively within the User Interface**.
 * **Submitting the workflows using Spark-Submit through the command line**.
 * **Scheduling for execution with your Scheduler of Choice**.
 
Interactively within the User Interface
------------------------------------------

Workflows can be executed from the browser by going into the Execute page of the workflow.


.. figure:: ../../../_assets/user-guide/workflow/4.PNG
   :alt: Workflow
   :width: 90%

Executing Workflows with Spark-Submit
--------------------------------------
 
Workflows are saved as JSON files.
Workflows can be submitted to be run on the cluster with Spark-Submit::
  
    spark-submit    --class    fire.execute.WorkflowExecuteFromFile    --master yarn    --deploy-mode client    --executor-memory 1G    --num-executors 1    --executor-cores 1       fire-core-1.4.2-jar-with-dependencies.jar       --postback-url http://<machine>:8080/messageFromSparkJob        --job-id 1         --workflow-file      kmeans.wf


In the above:

+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Parameter          | Details                                                                                                                                                                                                |
+====================+========================================================================================================================================================================================================+
| fire-core jar file | It is the fire-core jar file required code for executing the workflow. The fire-core jar file is in the fire-lib directory of the sparkflows install                                                   |
+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| postback-url       | http://<machine>:8080/messageFromSparkJob is the postback URL for fire UI. <machine> should be the machine name on which Sparkflows is running. 8080 should be the port on which Sparkflows is running |
+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| job-id             | 1 is the job id. It can be of any value for now                                                                                                                                                           |
+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| workflow-file      | kmeans.wf is the json workflow file containing the kmeans workflow in this case.                                                                                                                       |
+--------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+


 For providing extra variables to the workflow, the following parameters can be added to Spark-Submit::
 
    --var name1=value1   --var name2=value2    --var name3=value3
 
In the workflow, these variables can be used with $name1    $name2.
Specific nodes make use of the variables by substituting $name with the value provided for the name.
 
For running the workflow in Debug Mode, add the following parameters::

    --debug true
    

Workflow JSON
--------------
 
In Fire Insights, workflows are saved as JSON Strings. 
  
The View JSON Workflow page of the workflow displays the JSON representations of the workflow. 



.. figure:: ../../../_assets/user-guide/json-workflow.png
   :alt: Sparkflows Json Workflow
 
 
Scheduling Workflow Execution with Scheduler of Choice
----------------------------------------------------------
 
Since Fire workflows can be submitted with Spark-Submit, you can use your scheduler of choice for scheduling the execution of the workflows.
 
- Click on the 'Schedule' button of the workflow you want to schedule.

.. figure:: ../../../_assets/user-guide/workflow/5.PNG
   :alt: Workflow
   :width: 90%  
 
 
- Click on the 'Schedule New Job' tab for the workflow.
 
 .. figure:: ../../../_assets/user-guide/workflow/6.PNG
   :alt: Workflow
   :width: 60% 
 
 - Update the scheduled timing & email notifications after the success & failure of the workflow as per our requirements.
 
.. figure:: ../../../_assets/user-guide/workflow/7.PNG
   :alt: Workflow
   :width: 60%    

- Click on 'SUBMIT' to save the changes.

.. figure:: ../../../_assets/user-guide/workflow/8.PNG
   :alt: Workflow
   :width: 60%  

 
Debugging Workflows
-------------------
 
Many times it is helpful to be able to debug the workflows. One easy way is to check the 'Debug Checkbox' in the UI when executing the workflow.
 
Running in Debug Mode does a few things:

* Performs a count() after executing each processor. This makes it easier to debug and understand the pipeline. It takes out Fire Insightsâ€™ lazy execution from the picture.
* Displays the number of records processed at each stage.
* Displays more information for each SQL, etc., which are being executed.





